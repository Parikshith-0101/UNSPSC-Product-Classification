{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62a71013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parik\\AppData\\Roaming\\Python\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from rank_bm25 import BM25Okapi\n",
    "from typing import List, Dict, Tuple\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95a68ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, query_encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize embeddings\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"all-MiniLM-L6-v2\"\n",
    ")\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "425b0593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Segment Code</th>\n",
       "      <th>Segment Name</th>\n",
       "      <th>Family Code</th>\n",
       "      <th>Family Name</th>\n",
       "      <th>Class Code</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Commodity Code</th>\n",
       "      <th>Commodity Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000000</td>\n",
       "      <td>Live Plant and Animal Material and Accessories...</td>\n",
       "      <td>10100000</td>\n",
       "      <td>Live animals</td>\n",
       "      <td>10101500</td>\n",
       "      <td>Livestock</td>\n",
       "      <td>10101501</td>\n",
       "      <td>Cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000000</td>\n",
       "      <td>Live Plant and Animal Material and Accessories...</td>\n",
       "      <td>10100000</td>\n",
       "      <td>Live animals</td>\n",
       "      <td>10101500</td>\n",
       "      <td>Livestock</td>\n",
       "      <td>10101502</td>\n",
       "      <td>Dogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000000</td>\n",
       "      <td>Live Plant and Animal Material and Accessories...</td>\n",
       "      <td>10100000</td>\n",
       "      <td>Live animals</td>\n",
       "      <td>10101500</td>\n",
       "      <td>Livestock</td>\n",
       "      <td>10101504</td>\n",
       "      <td>Mink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000000</td>\n",
       "      <td>Live Plant and Animal Material and Accessories...</td>\n",
       "      <td>10100000</td>\n",
       "      <td>Live animals</td>\n",
       "      <td>10101500</td>\n",
       "      <td>Livestock</td>\n",
       "      <td>10101505</td>\n",
       "      <td>Rats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000000</td>\n",
       "      <td>Live Plant and Animal Material and Accessories...</td>\n",
       "      <td>10100000</td>\n",
       "      <td>Live animals</td>\n",
       "      <td>10101500</td>\n",
       "      <td>Livestock</td>\n",
       "      <td>10101506</td>\n",
       "      <td>Horses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Segment Code                                       Segment Name  \\\n",
       "0      10000000  Live Plant and Animal Material and Accessories...   \n",
       "1      10000000  Live Plant and Animal Material and Accessories...   \n",
       "2      10000000  Live Plant and Animal Material and Accessories...   \n",
       "3      10000000  Live Plant and Animal Material and Accessories...   \n",
       "4      10000000  Live Plant and Animal Material and Accessories...   \n",
       "\n",
       "   Family Code   Family Name  Class Code Class Name  Commodity Code  \\\n",
       "0     10100000  Live animals    10101500  Livestock        10101501   \n",
       "1     10100000  Live animals    10101500  Livestock        10101502   \n",
       "2     10100000  Live animals    10101500  Livestock        10101504   \n",
       "3     10100000  Live animals    10101500  Livestock        10101505   \n",
       "4     10100000  Live animals    10101500  Livestock        10101506   \n",
       "\n",
       "  Commodity Name  \n",
       "0           Cats  \n",
       "1           Dogs  \n",
       "2           Mink  \n",
       "3           Rats  \n",
       "4         Horses  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"G:/Dylog_Internship_Assessments/data/dylog_unspsc_data.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8e4a54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'live plant and animal material and accessories and supplies live animals livestock cats'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['corpus']=(df[\"Segment Name\"]+\" \"+df[\"Family Name\"]+\" \"+df[\"Class Name\"]+\" \"+df[\"Commodity Name\"]).str.lower()\n",
    "df[\"corpus\"].head(4)\n",
    "df[\"corpus\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "006c8255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='live plant and animal material and accessories and supplies live animals livestock cats' metadata={'Segment Code': 10000000, 'Segment Name': 'Live Plant and Animal Material and Accessories and Supplies', 'Family Code': 10100000, 'Family Name': 'Live animals', 'Class Code': 10101500, 'Class Name': 'Livestock', 'Commodity Code': 10101501, 'Commodity Name': 'Cats'}\n"
     ]
    }
   ],
   "source": [
    "chunks=[]\n",
    "for i,row in df.iterrows():\n",
    "    doc=Document(\n",
    "        page_content=row[\"corpus\"],\n",
    "        metadata={\n",
    "            \"Segment Code\": row[\"Segment Code\"],\n",
    "            \"Segment Name\": row[\"Segment Name\"],\n",
    "            \"Family Code\": row[\"Family Code\"],\n",
    "            \"Family Name\": row[\"Family Name\"],\n",
    "            \"Class Code\": row[\"Class Code\"],\n",
    "            \"Class Name\": row[\"Class Name\"],\n",
    "            \"Commodity Code\": row[\"Commodity Code\"],\n",
    "            \"Commodity Name\": row[\"Commodity Name\"],\n",
    "        }\n",
    "    )\n",
    "    chunks.append(doc)\n",
    "\n",
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b60a358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorstore=FAISS.from_documents(\n",
    "#     documents=chunks,\n",
    "#     embedding=embeddings,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eaf85e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vectorstore loaded with 71502 documents\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load vectorstore\n",
    "loaded_vectorstore = FAISS.load_local(\n",
    "    \"faiss.index\",\n",
    "    embeddings,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "print(f\" Vectorstore loaded with {len(loaded_vectorstore.docstore._dict)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45a0fe7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ProductFeatureExtractor loaded\n"
     ]
    }
   ],
   "source": [
    "#  Feature Extraction Module\n",
    "\n",
    "class ProductFeatureExtractor:\n",
    "    \"\"\"Extracts structured attributes from product descriptions\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.material_patterns = {\n",
    "            'stainless_steel': r'\\b(ss|stainless steel|304|316)\\b',\n",
    "            'carbon_steel': r'\\b(cs|carbon steel|mild steel)\\b',\n",
    "            'pvc': r'\\b(pvc|polyvinyl chloride)\\b',\n",
    "            'copper': r'\\b(copper|cu)\\b',\n",
    "            'aluminum': r'\\b(aluminum|al)\\b',\n",
    "            'galvanized': r'\\b(galvanized|hdg|hot dip)\\b',\n",
    "            'brass': r'\\b(brass)\\b',\n",
    "        }\n",
    "        \n",
    "        self.dimension_pattern = r'(\\d+(?:\\.\\d+)?)\\s*(?:x|by|×)\\s*(\\d+(?:\\.\\d+)?)'\n",
    "        self.volume_pattern = r'(\\d+(?:\\.\\d+)?)\\s*(?:gal|gallon|liter|l|ml|cc)'\n",
    "        self.pressure_pattern = r'(\\d+(?:\\.\\d+)?)\\s*(?:psi|bar|pa|kpa)'\n",
    "        self.power_pattern = r'(\\d+(?:\\.\\d+)?)\\s*(?:kw|hp|kbtu|btu|w|watt)'\n",
    "        self.voltage_pattern = r'(\\d+(?:\\.\\d+)?)\\s*(?:v|volt|ac|dc)'\n",
    "    \n",
    "    def extract_materials(self, text: str) -> dict:\n",
    "        text_lower = text.lower()\n",
    "        materials = {}\n",
    "        for material, pattern in self.material_patterns.items():\n",
    "            materials[f'has_{material}'] = bool(re.search(pattern, text_lower))\n",
    "        return materials\n",
    "    \n",
    "    def extract_specs(self, text: str) -> dict:\n",
    "        specs = {}\n",
    "        \n",
    "        vol_match = re.search(self.volume_pattern, text, re.IGNORECASE)\n",
    "        specs['has_volume'] = bool(vol_match)\n",
    "        specs['volume_value'] = float(vol_match.group(1)) if vol_match else 0.0\n",
    "        \n",
    "        pres_match = re.search(self.pressure_pattern, text, re.IGNORECASE)\n",
    "        specs['has_pressure'] = bool(pres_match)\n",
    "        specs['pressure_value'] = float(pres_match.group(1)) if pres_match else 0.0\n",
    "        \n",
    "        pow_match = re.search(self.power_pattern, text, re.IGNORECASE)\n",
    "        specs['has_power'] = bool(pow_match)\n",
    "        specs['power_value'] = float(pow_match.group(1)) if pow_match else 0.0\n",
    "        \n",
    "        volt_match = re.search(self.voltage_pattern, text, re.IGNORECASE)\n",
    "        specs['has_voltage'] = bool(volt_match)\n",
    "        specs['voltage_value'] = float(volt_match.group(1)) if volt_match else 0.0\n",
    "        \n",
    "        return specs\n",
    "    \n",
    "    def extract_keywords(self, text: str) -> dict:\n",
    "        text_lower = text.lower()\n",
    "        keywords = {\n",
    "            'is_heating': any(w in text_lower for w in ['heater', 'heating', 'furnace', 'boiler']),\n",
    "            'is_cooling': any(w in text_lower for w in ['cooler', 'cooling', 'chiller', 'fan']),\n",
    "            'is_pipe': any(w in text_lower for w in ['pipe', 'piping', 'tubing', 'coupling', 'fitting']),\n",
    "            'is_valve': any(w in text_lower for w in ['valve', 'vlv', 'gate', 'check']),\n",
    "            'is_electrical': any(w in text_lower for w in ['electrical', 'wire', 'cable', 'panel']),\n",
    "            'is_plumbing': any(w in text_lower for w in ['plumbing', 'toilet', 'sink', 'faucet']),\n",
    "        }\n",
    "        return keywords\n",
    "    \n",
    "    def extract_all(self, text: str) -> np.ndarray:\n",
    "        materials = self.extract_materials(text)\n",
    "        specs = self.extract_specs(text)\n",
    "        keywords = self.extract_keywords(text)\n",
    "        \n",
    "        features = {}\n",
    "        features.update(materials)\n",
    "        features.update(specs)\n",
    "        features.update(keywords)\n",
    "        \n",
    "        feature_vector = np.array([\n",
    "            features['has_stainless_steel'],\n",
    "            features['has_carbon_steel'],\n",
    "            features['has_pvc'],\n",
    "            features['has_copper'],\n",
    "            features['has_aluminum'],\n",
    "            features['has_galvanized'],\n",
    "            features['has_brass'],\n",
    "            features['has_volume'],\n",
    "            features['volume_value'],\n",
    "            features['has_pressure'],\n",
    "            features['pressure_value'],\n",
    "            features['has_power'],\n",
    "            features['power_value'],\n",
    "            features['has_voltage'],\n",
    "            features['voltage_value'],\n",
    "            features['is_heating'],\n",
    "            features['is_cooling'],\n",
    "            features['is_pipe'],\n",
    "            features['is_valve'],\n",
    "            features['is_electrical'],\n",
    "            features['is_plumbing'],\n",
    "        ], dtype=np.float32)\n",
    "        \n",
    "        return feature_vector\n",
    "\n",
    "print(\" ProductFeatureExtractor loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58848adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded queries: 50 items\n",
      "   Columns: ['Search Query', 'UNSPSC Commodity Name']\n",
      " Loaded products: 100 items\n",
      "   Columns: ['Original Description', 'UNSPSC Commodity Name']\n",
      "\n",
      "📋 Sample Product Description:\n",
      "BW RG2PV75H6X 75 GAL LP GAS POWER VENTED WATER HEATER STANDARD W/SIDE CONNECTIONS FOR SPACE HTG 76KBTU 6YR 70\"\"H X 26\"\"DIA\n",
      "Checking and fixing df columns...\n",
      "Current columns in df: ['Segment Code', 'Segment Name', 'Family Code', 'Family Name', 'Class Code', 'Class Name', 'Commodity Code', 'Commodity Name', 'corpus']\n",
      "\n",
      "\n",
      " Statistics:\n",
      "  - Total corpus entries: 71502\n",
      "  - Average corpus length: 130 chars\n",
      "  - Corpus with content: 71502\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Segment Code</th>\n",
       "      <th>Segment Name</th>\n",
       "      <th>Family Code</th>\n",
       "      <th>Family Name</th>\n",
       "      <th>Class Code</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Commodity Code</th>\n",
       "      <th>Commodity Name</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000000</td>\n",
       "      <td>Live Plant and Animal Material and Accessories...</td>\n",
       "      <td>10100000</td>\n",
       "      <td>Live animals</td>\n",
       "      <td>10101500</td>\n",
       "      <td>Livestock</td>\n",
       "      <td>10101501</td>\n",
       "      <td>Cats</td>\n",
       "      <td>live plant and animal material and accessories...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000000</td>\n",
       "      <td>Live Plant and Animal Material and Accessories...</td>\n",
       "      <td>10100000</td>\n",
       "      <td>Live animals</td>\n",
       "      <td>10101500</td>\n",
       "      <td>Livestock</td>\n",
       "      <td>10101502</td>\n",
       "      <td>Dogs</td>\n",
       "      <td>live plant and animal material and accessories...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000000</td>\n",
       "      <td>Live Plant and Animal Material and Accessories...</td>\n",
       "      <td>10100000</td>\n",
       "      <td>Live animals</td>\n",
       "      <td>10101500</td>\n",
       "      <td>Livestock</td>\n",
       "      <td>10101504</td>\n",
       "      <td>Mink</td>\n",
       "      <td>live plant and animal material and accessories...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000000</td>\n",
       "      <td>Live Plant and Animal Material and Accessories...</td>\n",
       "      <td>10100000</td>\n",
       "      <td>Live animals</td>\n",
       "      <td>10101500</td>\n",
       "      <td>Livestock</td>\n",
       "      <td>10101505</td>\n",
       "      <td>Rats</td>\n",
       "      <td>live plant and animal material and accessories...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000000</td>\n",
       "      <td>Live Plant and Animal Material and Accessories...</td>\n",
       "      <td>10100000</td>\n",
       "      <td>Live animals</td>\n",
       "      <td>10101500</td>\n",
       "      <td>Livestock</td>\n",
       "      <td>10101506</td>\n",
       "      <td>Horses</td>\n",
       "      <td>live plant and animal material and accessories...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Segment Code                                       Segment Name  \\\n",
       "0      10000000  Live Plant and Animal Material and Accessories...   \n",
       "1      10000000  Live Plant and Animal Material and Accessories...   \n",
       "2      10000000  Live Plant and Animal Material and Accessories...   \n",
       "3      10000000  Live Plant and Animal Material and Accessories...   \n",
       "4      10000000  Live Plant and Animal Material and Accessories...   \n",
       "\n",
       "   Family Code   Family Name  Class Code Class Name  Commodity Code  \\\n",
       "0     10100000  Live animals    10101500  Livestock        10101501   \n",
       "1     10100000  Live animals    10101500  Livestock        10101502   \n",
       "2     10100000  Live animals    10101500  Livestock        10101504   \n",
       "3     10100000  Live animals    10101500  Livestock        10101505   \n",
       "4     10100000  Live animals    10101500  Livestock        10101506   \n",
       "\n",
       "  Commodity Name                                             corpus  \n",
       "0           Cats  live plant and animal material and accessories...  \n",
       "1           Dogs  live plant and animal material and accessories...  \n",
       "2           Mink  live plant and animal material and accessories...  \n",
       "3           Rats  live plant and animal material and accessories...  \n",
       "4         Horses  live plant and animal material and accessories...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training queries\n",
    "queries_df = pd.read_csv(\"G:/Dylog_Internship_Assessments/data/dylog_search_queries_unspsc.csv\")\n",
    "print(f\" Loaded queries: {len(queries_df)} items\")\n",
    "print(f\"   Columns: {queries_df.columns.tolist()}\")\n",
    "\n",
    "# Load test products\n",
    "products_df = pd.read_csv(\"G:/Dylog_Internship_Assessments/data/dylog_sample_product_unspsc.csv\")\n",
    "print(f\" Loaded products: {len(products_df)} items\")\n",
    "print(f\"   Columns: {products_df.columns.tolist()}\")\n",
    "\n",
    "# Preview first row\n",
    "print(\"\\n📋 Sample Product Description:\")\n",
    "print(products_df.iloc[0]['Original Description'])\n",
    "\n",
    "\n",
    "print(\"Checking and fixing df columns...\")\n",
    "print(f\"Current columns in df: {df.columns.tolist()}\\n\")\n",
    "\n",
    "# Create corpus column if missing\n",
    "# if 'corpus' not in df.columns:\n",
    "#     print(\"Creating 'corpus' column...\")\n",
    "#     df['corpus'] = (\n",
    "#         df[\"Segment Name\"] + \" \" + \n",
    "#         df[\"Family Name\"] + \" \" + \n",
    "#         df[\"Class Name\"] + \" \" + \n",
    "#         df[\"Commodity Name\"]\n",
    "#     ).str.lower()\n",
    "#     print(\" Corpus column created successfully!\")\n",
    "#     print(f\"\\nSample corpus entries:\")\n",
    "#     for i in range(3):\n",
    "#         print(f\"  {i+1}. {df['corpus'].iloc[i][:80]}...\")\n",
    "# else:\n",
    "#     print(\" Corpus column already exists\")\n",
    "\n",
    "# Verify corpus matches vectorstore documents\n",
    "print(f\"\\n Statistics:\")\n",
    "print(f\"  - Total corpus entries: {len(df['corpus'])}\")\n",
    "print(f\"  - Average corpus length: {df['corpus'].str.len().mean():.0f} chars\")\n",
    "print(f\"  - Corpus with content: {df['corpus'].notna().sum()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeaaeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentInformedHierarchicalRouter:\n",
    "    \"\"\"Uses retrieved documents to constrain hierarchy search\"\"\"\n",
    "    \n",
    "    def __init__(self, catalog_df):\n",
    "        self.catalog = catalog_df\n",
    "        self.build_hierarchy()\n",
    "    \n",
    "    def build_hierarchy(self):\n",
    "        \"\"\"Build routing structures\"\"\"\n",
    "        # Segment → Families\n",
    "        self.segment_to_families = {}\n",
    "        for _, row in self.catalog.iterrows():\n",
    "            seg = row['Segment Name']\n",
    "            fam = row['Family Name']\n",
    "            if seg not in self.segment_to_families:\n",
    "                self.segment_to_families[seg] = set()\n",
    "            self.segment_to_families[seg].add(fam)\n",
    "        \n",
    "        # Family → Classes\n",
    "        self.family_to_classes = {}\n",
    "        for _, row in self.catalog.iterrows():\n",
    "            fam = row['Family Name']\n",
    "            cls = row['Class Name']\n",
    "            if fam not in self.family_to_classes:\n",
    "                self.family_to_classes[fam] = set()\n",
    "            self.family_to_classes[fam].add(cls)\n",
    "        \n",
    "        # Class → Commodities\n",
    "        self.class_to_commodities = {}\n",
    "        for _, row in self.catalog.iterrows():\n",
    "            cls = row['Class Name']\n",
    "            comm = row['Commodity Name']\n",
    "            if cls not in self.class_to_commodities:\n",
    "                self.class_to_commodities[cls] = set()\n",
    "            self.class_to_commodities[cls].add(comm)\n",
    "        \n",
    "        # Commodity → Full metadata (for reverse lookup)\n",
    "        self.commodity_to_hierarchy = {}\n",
    "        for _, row in self.catalog.iterrows():\n",
    "            comm = row['Commodity Name']\n",
    "            self.commodity_to_hierarchy[comm] = {\n",
    "                'segment': row['Segment Name'],\n",
    "                'family': row['Family Name'],\n",
    "                'class': row['Class Name']\n",
    "            }\n",
    "        \n",
    "        print(f\" Hierarchy built:\")\n",
    "        print(f\"   - {len(self.segment_to_families)} segments\")\n",
    "        print(f\"   - {len(self.family_to_classes)} families\")\n",
    "        print(f\"   - {len(self.class_to_commodities)} classes\")\n",
    "    \n",
    "    def route_from_documents(self, retrieved_candidates, top_k=5):\n",
    "        \"\"\"\n",
    "        Use top-k retrieved documents to inform hierarchy routing.\n",
    "        \n",
    "        Args:\n",
    "            retrieved_candidates: List of dicts from HybridRetriever with metadata\n",
    "            top_k: Number of top documents to analyze\n",
    "        \n",
    "        Returns:\n",
    "            Dict with constrained hierarchy paths\n",
    "        \"\"\"\n",
    "        # Extract hierarchy info from top-k documents\n",
    "        top_docs = retrieved_candidates[:top_k]\n",
    "        \n",
    "        segment_counts = {}\n",
    "        family_counts = {}\n",
    "        class_counts = {}\n",
    "        \n",
    "        for doc in top_docs:\n",
    "            metadata = doc.get('metadata', {})\n",
    "            \n",
    "            segment = metadata.get('Segment Name')\n",
    "            family = metadata.get('Family Name')\n",
    "            cls = metadata.get('Class Name')\n",
    "            \n",
    "            if segment:\n",
    "                segment_counts[segment] = segment_counts.get(segment, 0) + 1\n",
    "            if family:\n",
    "                family_counts[family] = family_counts.get(family, 0) + 1\n",
    "            if cls:\n",
    "                class_counts[cls] = class_counts.get(cls, 0) + 1\n",
    "        \n",
    "        # Get top segments (by frequency in retrieved docs)\n",
    "        top_segments = sorted(segment_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Get families constrained by top segments\n",
    "        valid_families = set()\n",
    "        for segment, _ in top_segments:\n",
    "            valid_families.update(self.segment_to_families.get(segment, set()))\n",
    "        \n",
    "        top_families = [(f, family_counts.get(f, 0)) for f in valid_families]\n",
    "        top_families = sorted(top_families, key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Get classes constrained by top families\n",
    "        valid_classes = set()\n",
    "        for family, _ in top_families:\n",
    "            valid_classes.update(self.family_to_classes.get(family, set()))\n",
    "        \n",
    "        top_classes = [(c, class_counts.get(c, 0)) for c in valid_classes]\n",
    "        top_classes = sorted(top_classes, key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Get commodities constrained by top classes\n",
    "        valid_commodities = set()\n",
    "        for cls, _ in top_classes:\n",
    "            valid_commodities.update(self.class_to_commodities.get(cls, set()))\n",
    "        \n",
    "        return {\n",
    "            'top_segments': dict(top_segments[:3]),\n",
    "            'top_families': dict(top_families[:5]),\n",
    "            'top_classes': dict(top_classes[:5]),\n",
    "            'valid_commodities': valid_commodities,\n",
    "            'num_constrained': len(valid_commodities)\n",
    "        }\n",
    "    \n",
    "    def filter_candidates_by_hierarchy(self, candidates, hierarchy_info):\n",
    "        \"\"\"\n",
    "        Boost candidates that fall within hierarchy constraints.\n",
    "        \n",
    "        Args:\n",
    "            candidates: Full candidate list from evaluation\n",
    "            hierarchy_info: Output from route_from_documents()\n",
    "        \n",
    "        Returns:\n",
    "            Candidates with hierarchy_score added\n",
    "        \"\"\"\n",
    "        valid_commodities = hierarchy_info['valid_commodities']\n",
    "        \n",
    "        for candidate in candidates:\n",
    "            commodity_name = candidate.get('commodity_name', '')\n",
    "            in_hierarchy = commodity_name in valid_commodities\n",
    "            \n",
    "            # Boost score if in hierarchy\n",
    "            if in_hierarchy:\n",
    "                candidate['hierarchy_boost'] = 1.3  # 30% boost\n",
    "            else:\n",
    "                candidate['hierarchy_boost'] = 1.0\n",
    "            \n",
    "            candidate['in_hierarchy'] = in_hierarchy\n",
    "        \n",
    "        return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "924e84aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step 1: Verifying data compatibility...\n",
      "\n",
      "======================================================================\n",
      "DATA COMPATIBILITY CHECK\n",
      "======================================================================\n",
      "\n",
      "1️ Catalog Info:\n",
      "   Total commodities: 71502\n",
      "   Sample names: ['canned or jarred red beard bunching onions', 'canned or jarred organic maraschino cherries', 'educational or teacher associations']\n",
      "\n",
      "2️ Products Info:\n",
      "   Total products: 100\n",
      "   Unique commodity names: 72\n",
      "   Sample names: ['refrigerant compressors', 'towel bar or ring or stand or hook', 'furnaces']\n",
      "\n",
      "3️ Matching Analysis:\n",
      "    Matching names: 72/72\n",
      "    Missing from catalog: 0\n",
      "\n",
      "   Match rate: 100.0%\n",
      "======================================================================\n",
      "\n",
      "\n",
      "🔧 Step 2: Initializing evaluator...\n",
      " Built lookups:\n",
      "   - Code → Hierarchy: 71502 entries\n",
      "   - Name → Code: 71502 entries\n",
      "\n",
      " Products DF columns: ['Original Description', 'UNSPSC Commodity Name']\n",
      "\n",
      " Step 3: Running evaluation...\n",
      "\n",
      "======================================================================\n",
      "STARTING EVALUATION\n",
      "======================================================================\n",
      "\n",
      " Product #0:\n",
      "  Description: BW RG2PV75H6X 75 GAL LP GAS POWER VENTED WATER HEATER STANDA...\n",
      "  True Commodity: Domestic water heaters\n",
      "  True Code: 40101825\n",
      "  True Segment: Distribution and Conditioning Systems and Equipment and Components\n",
      "  True Family: Heating and ventilation and air circulation\n",
      "  True Class: Heating equipment and parts and accessories\n",
      "  Top 3 Predictions:\n",
      "    1. gas fueled fireplace b vent (code: 40102102)\n",
      "    2. tungsten w (code: 12141747)\n",
      "    3. space heaters (code: 40101819)\n",
      "\n",
      " Product #1:\n",
      "  Description: VERSIPRO BISC ELG CFWC WOOD SEAT SI SW-985 ORANGE CITRUS CRA...\n",
      "  True Commodity: Toilet seat\n",
      "  True Code: 30181603\n",
      "  True Segment: Structures and Building and Construction and Manufacturing Components and Supplies\n",
      "  True Family: Plumbing fixtures\n",
      "  True Class: Non sanitary residential fixtures\n",
      "  Top 3 Predictions:\n",
      "    1. orange concentrate (code: 50202423)\n",
      "    2. orange juice (code: 50202409)\n",
      "    3. dried organic limequat oranges (code: 50335023)\n",
      "\n",
      " Product #2:\n",
      "  Description: 2 3000# Forged Steel Threaded Half Coupling FPT x FPT...\n",
      "  True Commodity: Forged steel pipe half coupling\n",
      "  True Code: 40173003\n",
      "  True Segment: Distribution and Conditioning Systems and Equipment and Components\n",
      "  True Family: Pipe piping and pipe fittings\n",
      "  True Class: Pipe half couplings\n",
      "  Top 3 Predictions:\n",
      "    1. forged steel pipe half coupling (code: 40173003)\n",
      "    2. stainless steel pipe half coupling (code: 40173005)\n",
      "    3. coupling half (code: 31163012)\n",
      "\n",
      " Evaluation complete:\n",
      "   Total evaluated: 100\n",
      "   Skipped: 0\n",
      "\n",
      "======================================================================\n",
      "FINAL EVALUATION RESULTS\n",
      "======================================================================\n",
      "Top-1 Accuracy           :  21.00%\n",
      "Precision@1              :  21.00%\n",
      "Recall@1                 :  21.00%\n",
      "Segment Acc @1           :  42.00%\n",
      "Family Acc @1            :  34.00%\n",
      "Class Acc @1             :  26.00%\n",
      "Top-5 Accuracy           :  33.00%\n",
      "Precision@5              :   6.60%\n",
      "Recall@5                 :  33.00%\n",
      "Segment Acc @5           :  58.00%\n",
      "Family Acc @5            :  50.00%\n",
      "Class Acc @5             :  40.00%\n",
      "Top-10 Accuracy          :  36.00%\n",
      "Precision@10             :   3.60%\n",
      "Recall@10                :  36.00%\n",
      "Segment Acc @10          :  66.00%\n",
      "Family Acc @10           :  55.00%\n",
      "Class Acc @10            :  44.00%\n",
      "Total Evaluated          : 100\n",
      "Skipped                  : 0\n",
      "======================================================================\n",
      "\n",
      " SANITY CHECK:\n",
      "   Top-1 Accuracy: 21.0%\n",
      "   Segment Acc @1: 42.0%\n",
      "    PASS: Segment ≥ Commodity (as expected)\n",
      "\n",
      "\n",
      " All classes are defined\n"
     ]
    }
   ],
   "source": [
    "class TextCleaner:\n",
    "    \"\"\"Cleans and normalizes product descriptions and queries\"\"\"\n",
    "    \n",
    "    def __init__(self, mappings=None, remove_arbitrary_alphanum=False):\n",
    "        self.mappings = mappings or {\n",
    "            \"pvc\": \"polyvinyl chloride\",\n",
    "            \"ss\": \"stainless steel\", \n",
    "            \"cs\": \"carbon steel\",\n",
    "            \"vlv\": \"valve\",\n",
    "            \"adpt\": \"adapter\",\n",
    "            \"bush\": \"bushing\",\n",
    "            \"cplg\": \"coupling\",\n",
    "            \"ftg\": \"fitting\",\n",
    "            \"tee\": \"t-junction\"\n",
    "        }\n",
    "        self.remove_arbitrary_alphanum = remove_arbitrary_alphanum\n",
    "        self.arbitrary_pattern = re.compile(r'\\b[a-z0-9]{8,}\\b')\n",
    "    \n",
    "    def clean(self, text: str) -> str:\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "        \n",
    "        text = text.lower().strip()\n",
    "        \n",
    "        # Apply mappings\n",
    "        for k, v in self.mappings.items():\n",
    "            text = text.replace(k, v)\n",
    "        \n",
    "        # Remove arbitrary patterns if enabled\n",
    "        if self.remove_arbitrary_alphanum:\n",
    "            text = self.arbitrary_pattern.sub('', text)\n",
    "        \n",
    "        # Remove special characters except spaces and numbers\n",
    "        text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        return text\n",
    "\n",
    "\n",
    "def convert_docs_to_dicts(results: List[Tuple], include_scores=True) -> List[Dict]:\n",
    "    \"\"\"Converts FAISS search results to standardized dicts\"\"\"\n",
    "    converted = []\n",
    "    for doc, score in results:\n",
    "        entry = {\n",
    "            \"doc_text\": doc.page_content,\n",
    "            \"metadata\": doc.metadata,\n",
    "        }\n",
    "        if include_scores:\n",
    "            entry[\"sem_score\"] = float(score)\n",
    "        converted.append(entry)\n",
    "    return converted\n",
    "\n",
    "\n",
    "class HybridRetriever:\n",
    "    \"\"\"Combines semantic (FAISS) and lexical (BM25) retrieval\"\"\"\n",
    "    \n",
    "    def __init__(self, df: pd.DataFrame, vectorstore, embeddings, cleaner=None):\n",
    "        self.df = df\n",
    "        self.vectorstore = vectorstore\n",
    "        self.embeddings = embeddings\n",
    "        self.cleaner = cleaner or TextCleaner()\n",
    "        \n",
    "        # Build BM25 index on corpus\n",
    "        self.tokenized_docs = [\n",
    "            self.cleaner.clean(doc).split() \n",
    "            for doc in df['corpus'].tolist()\n",
    "        ]\n",
    "        \n",
    "        self.bm25 = BM25Okapi(self.tokenized_docs)\n",
    "        print(\" BM25 index ready\")\n",
    "    \n",
    "    def retrieve(self, query: str, top_k=50) -> List[Dict]:\n",
    "        \"\"\"Retrieve top-k candidates using hybrid search\"\"\"\n",
    "        query_clean = self.cleaner.clean(query)\n",
    "        \n",
    "        # 1. Semantic retrieval (FAISS)\n",
    "        sem_results = self.vectorstore.similarity_search_with_score(query_clean, k=top_k)\n",
    "        sem_candidates = convert_docs_to_dicts(sem_results, include_scores=True)\n",
    "        \n",
    "        # 2. Lexical retrieval (BM25)\n",
    "        tokenized_query = query_clean.split()\n",
    "        bm25_scores = self.bm25.get_scores(tokenized_query)\n",
    "        top_indices = np.argsort(-bm25_scores)[:top_k]\n",
    "        \n",
    "        # Merge results\n",
    "        corpus_to_candidate = {c['doc_text']: c for c in sem_candidates}\n",
    "        \n",
    "        for idx in top_indices:\n",
    "            corpus_text = self.df.iloc[idx]['corpus']\n",
    "            commodity_name = self.df.iloc[idx]['Commodity Name']\n",
    "            commodity_code = self.df.iloc[idx]['Commodity Code']\n",
    "            lex_score = float(bm25_scores[idx])\n",
    "            \n",
    "            if corpus_text in corpus_to_candidate:\n",
    "                corpus_to_candidate[corpus_text]['lex_score'] = lex_score\n",
    "            else:\n",
    "                corpus_to_candidate[corpus_text] = {\n",
    "                    'doc_text': corpus_text,\n",
    "                    'commodity_name': commodity_name,\n",
    "                    'commodity_code': commodity_code,\n",
    "                    'metadata': self.df.iloc[idx].to_dict(),\n",
    "                    'sem_score': 0.0,\n",
    "                    'lex_score': lex_score\n",
    "                }\n",
    "        \n",
    "        # Ensure all candidates have both scores\n",
    "        candidates = list(corpus_to_candidate.values())\n",
    "        for c in candidates:\n",
    "            c.setdefault('sem_score', 0.0)\n",
    "            c.setdefault('lex_score', 0.0)\n",
    "            if 'commodity_name' not in c:\n",
    "                c['commodity_name'] = c['metadata'].get('Commodity Name', '')\n",
    "            if 'commodity_code' not in c:\n",
    "                c['commodity_code'] = c['metadata'].get('Commodity Code', '')\n",
    "        \n",
    "        return candidates\n",
    "\n",
    "\n",
    "class CrossEncoderReranker:\n",
    "    \"\"\"Reranks candidates using a cross-encoder model\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name=\"cross-encoder/ms-marco-MiniLM-L-6-v2\", device=None):\n",
    "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        print(f\"✅ Cross-encoder loaded on {self.device}\")\n",
    "    \n",
    "    def rerank(self, query: str, candidates: List[Dict], top_n=10) -> List[Dict]:\n",
    "        if not candidates:\n",
    "            return []\n",
    "        \n",
    "        candidate_texts = [c['doc_text'] for c in candidates]\n",
    "        \n",
    "        encodings = self.tokenizer(\n",
    "            [query] * len(candidate_texts),\n",
    "            candidate_texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            scores = self.model(**encodings).logits.squeeze(-1).cpu().numpy()\n",
    "        \n",
    "        for i, cand in enumerate(candidates):\n",
    "            cand['cross_score'] = float(scores[i])\n",
    "        \n",
    "        reranked = sorted(candidates, key=lambda x: x['cross_score'], reverse=True)\n",
    "        return reranked[:top_n]\n",
    "\n",
    "\n",
    "class ScoreMerger:\n",
    "    \"\"\"Combines hybrid retrieval scores with cross-encoder scores\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha=0.4, beta=0.6):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "    \n",
    "    def normalize_scores(self, scores: np.ndarray) -> np.ndarray:\n",
    "        scores = np.array(scores, dtype=np.float32)\n",
    "        if scores.size == 0:\n",
    "            return scores\n",
    "        \n",
    "        min_s, max_s = scores.min(), scores.max()\n",
    "        if max_s - min_s == 0:\n",
    "            return np.ones_like(scores)\n",
    "        \n",
    "        return (scores - min_s) / (max_s - min_s)\n",
    "    \n",
    "    def merge(self, candidates: List[Dict]) -> List[Dict]:\n",
    "        if not candidates:\n",
    "            return []\n",
    "        \n",
    "        sem_scores = np.array([c.get('sem_score', 0) for c in candidates])\n",
    "        lex_scores = np.array([c.get('lex_score', 0) for c in candidates])\n",
    "        cross_scores = np.array([c.get('cross_score', 0) for c in candidates])\n",
    "        \n",
    "        hybrid_scores = self.normalize_scores(sem_scores + lex_scores)\n",
    "        cross_scores_norm = self.normalize_scores(cross_scores)\n",
    "        \n",
    "        final_scores = self.alpha * hybrid_scores + self.beta * cross_scores_norm\n",
    "        \n",
    "        for i, c in enumerate(candidates):\n",
    "            c['final_score'] = float(final_scores[i])\n",
    "        \n",
    "        return sorted(candidates, key=lambda x: x['final_score'], reverse=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# FIXED PRODUCT EVALUATOR - Works with Commodity NAME instead of CODE\n",
    "# ============================================================================\n",
    "\n",
    "class ProductEvaluator:\n",
    "    \"\"\"Evaluates retrieval using commodity NAMES (not codes) with proper hierarchy metrics\"\"\"\n",
    "    \n",
    "    def __init__(self, products_df: pd.DataFrame, catalog_df: pd.DataFrame, \n",
    "                 retriever, reranker, merger, cleaner=None):\n",
    "        self.products_df = products_df\n",
    "        self.catalog_df = catalog_df\n",
    "        self.retriever = retriever\n",
    "        self.reranker = reranker\n",
    "        self.merger = merger\n",
    "        self.cleaner = cleaner or TextCleaner()\n",
    "        self.hierarchical_router = DocumentInformedHierarchicalRouter(catalog_df)\n",
    "        \n",
    "        \n",
    "        # Build TWO lookups:\n",
    "        # 1. Commodity Code → Full hierarchy\n",
    "        self.code_to_hierarchy = {}\n",
    "        for _, row in catalog_df.iterrows():\n",
    "            code = row['Commodity Code']\n",
    "            self.code_to_hierarchy[code] = {\n",
    "                'Segment Name': row['Segment Name'],\n",
    "                'Family Name': row['Family Name'],\n",
    "                'Class Name': row['Class Name'],\n",
    "                'Commodity Name': row['Commodity Name']\n",
    "            }\n",
    "        \n",
    "        # 2. Commodity Name → Commodity Code (for reverse lookup)\n",
    "        self.name_to_code = {}\n",
    "        for _, row in catalog_df.iterrows():\n",
    "            name = row['Commodity Name'].strip().lower()\n",
    "            code = row['Commodity Code']\n",
    "            self.name_to_code[name] = code\n",
    "        \n",
    "        print(f\"✅ Built lookups:\")\n",
    "        print(f\"   - Code → Hierarchy: {len(self.code_to_hierarchy)} entries\")\n",
    "        print(f\"   - Name → Code: {len(self.name_to_code)} entries\")\n",
    "        print(f\"\\n📋 Products DF columns: {products_df.columns.tolist()}\")\n",
    "    \n",
    "    def evaluate(self, retrieve_k=50, rerank_k=20, top_k_list=[1, 5, 10]) -> Dict:\n",
    "        \"\"\"Evaluate retrieval with proper name-based matching\"\"\"\n",
    "        \n",
    "        metrics = defaultdict(int)\n",
    "        precision_at_k = {k: [] for k in top_k_list}\n",
    "        recall_at_k = {k: [] for k in top_k_list}\n",
    "        \n",
    "        segment_hits = {k: 0 for k in top_k_list}\n",
    "        family_hits = {k: 0 for k in top_k_list}\n",
    "        class_hits = {k: 0 for k in top_k_list}\n",
    "        \n",
    "        total = 0\n",
    "        skipped = 0\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"STARTING EVALUATION\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        for idx, row in self.products_df.iterrows():\n",
    "            # Get description\n",
    "            description = row.get('Original Description', '')\n",
    "            \n",
    "            # Get true commodity NAME (this is what we have in products_df)\n",
    "            true_commodity_name = row.get('UNSPSC Commodity Name', '')\n",
    "            \n",
    "            # Skip if missing\n",
    "            if not description or not true_commodity_name:\n",
    "                skipped += 1\n",
    "                if idx < 3:\n",
    "                    print(f\"⚠️ Skipping row {idx}: no description or commodity name\")\n",
    "                continue\n",
    "            \n",
    "            # Convert name → code using catalog\n",
    "            true_commodity_name_clean = true_commodity_name.strip().lower()\n",
    "            true_commodity_code = self.name_to_code.get(true_commodity_name_clean)\n",
    "            \n",
    "            if not true_commodity_code:\n",
    "                skipped += 1\n",
    "                if idx < 3:\n",
    "                    print(f\"⚠️ Skipping row {idx}: commodity '{true_commodity_name}' not found in catalog\")\n",
    "                continue\n",
    "            \n",
    "            total += 1\n",
    "            \n",
    "            # Get true hierarchy from catalog\n",
    "            true_hierarchy = self.code_to_hierarchy.get(true_commodity_code, {})\n",
    "            true_segment = true_hierarchy.get('Segment Name', '')\n",
    "            true_family = true_hierarchy.get('Family Name', '')\n",
    "            true_class = true_hierarchy.get('Class Name', '')\n",
    "            \n",
    "            # Debug first 3 products\n",
    "            if idx < 3:\n",
    "                print(f\"\\n📋 Product #{idx}:\")\n",
    "                print(f\"  Description: {description[:60]}...\")\n",
    "                print(f\"  True Commodity: {true_commodity_name}\")\n",
    "                print(f\"  True Code: {true_commodity_code}\")\n",
    "                print(f\"  True Segment: {true_segment}\")\n",
    "                print(f\"  True Family: {true_family}\")\n",
    "                print(f\"  True Class: {true_class}\")\n",
    "            \n",
    "            try:\n",
    "                # Retrieve candidates\n",
    "                candidates = self.retriever.retrieve(description, top_k=retrieve_k)\n",
    "                \n",
    "                if not candidates:\n",
    "                    continue\n",
    "                \n",
    "                # Rerank\n",
    "                candidates = self.reranker.rerank(description, candidates, top_n=rerank_k)\n",
    "                final_candidates = self.merger.merge(candidates)\n",
    "                \n",
    "                # Extract predicted codes and names\n",
    "                pred_codes = []\n",
    "                pred_names = []\n",
    "                \n",
    "                for c in final_candidates:\n",
    "                    code = c.get('commodity_code')\n",
    "                    name = c.get('commodity_name', '')\n",
    "                    \n",
    "                    try:\n",
    "                        pred_codes.append(int(code))\n",
    "                        pred_names.append(name.strip().lower())\n",
    "                    except (ValueError, TypeError):\n",
    "                        pred_codes.append(None)\n",
    "                        pred_names.append('')\n",
    "                \n",
    "                # Debug first 3 products\n",
    "                if idx < 3:\n",
    "                    print(f\"  Top 3 Predictions:\")\n",
    "                    for i in range(min(3, len(pred_names))):\n",
    "                        print(f\"    {i+1}. {pred_names[i][:50]} (code: {pred_codes[i]})\")\n",
    "                \n",
    "                # Evaluate each K\n",
    "                for k in top_k_list:\n",
    "                    top_k_codes = pred_codes[:k]\n",
    "                    top_k_names = pred_names[:k]\n",
    "                    \n",
    "                    # Commodity match (by CODE or NAME)\n",
    "                    commodity_match = (\n",
    "                        true_commodity_code in top_k_codes or\n",
    "                        true_commodity_name_clean in top_k_names\n",
    "                    )\n",
    "                    \n",
    "                    metrics[f'top{k}'] += int(commodity_match)\n",
    "                    precision_at_k[k].append(int(commodity_match) / k)\n",
    "                    recall_at_k[k].append(int(commodity_match) / 1)\n",
    "                    \n",
    "                    # Hierarchy matching\n",
    "                    segment_match = False\n",
    "                    family_match = False\n",
    "                    class_match = False\n",
    "                    \n",
    "                    for pred_code in top_k_codes:\n",
    "                        if pred_code is None:\n",
    "                            continue\n",
    "                        \n",
    "                        pred_hierarchy = self.code_to_hierarchy.get(pred_code, {})\n",
    "                        \n",
    "                        if pred_hierarchy.get('Segment Name') == true_segment:\n",
    "                            segment_match = True\n",
    "                        if pred_hierarchy.get('Family Name') == true_family:\n",
    "                            family_match = True\n",
    "                        if pred_hierarchy.get('Class Name') == true_class:\n",
    "                            class_match = True\n",
    "                    \n",
    "                    segment_hits[k] += int(segment_match)\n",
    "                    family_hits[k] += int(family_match)\n",
    "                    class_hits[k] += int(class_match)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"\\n Error processing row {idx}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "        \n",
    "        print(f\"\\n Evaluation complete:\")\n",
    "        print(f\"   Total evaluated: {total}\")\n",
    "        print(f\"   Skipped: {skipped}\")\n",
    "        \n",
    "        if total == 0:\n",
    "            return {\n",
    "                \"error\": \"No valid products to evaluate\", \n",
    "                \"skipped\": skipped,\n",
    "                \"hint\": \"Check if commodity names in products_df match catalog exactly\"\n",
    "            }\n",
    "        \n",
    "        # Calculate final results\n",
    "        results = {}\n",
    "        for k in top_k_list:\n",
    "            results[f\"Top-{k} Accuracy\"] = (metrics[f'top{k}'] / total) * 100\n",
    "            results[f\"Precision@{k}\"] = np.mean(precision_at_k[k]) * 100 if precision_at_k[k] else 0\n",
    "            results[f\"Recall@{k}\"] = np.mean(recall_at_k[k]) * 100 if recall_at_k[k] else 0\n",
    "            results[f\"Segment Acc @{k}\"] = (segment_hits[k] / total) * 100\n",
    "            results[f\"Family Acc @{k}\"] = (family_hits[k] / total) * 100\n",
    "            results[f\"Class Acc @{k}\"] = (class_hits[k] / total) * 100\n",
    "        \n",
    "        results[\"Total Evaluated\"] = total\n",
    "        results[\"Skipped\"] = skipped\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# VERIFICATION HELPER\n",
    "# ============================================================================\n",
    "def verify_data_compatibility(products_df, catalog_df):\n",
    "    \"\"\"Check if product commodity names exist in catalog\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"DATA COMPATIBILITY CHECK\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Get all commodity names from catalog\n",
    "    catalog_names = set(catalog_df['Commodity Name'].str.strip().str.lower())\n",
    "    \n",
    "    print(f\"\\n1️ Catalog Info:\")\n",
    "    print(f\"   Total commodities: {len(catalog_names)}\")\n",
    "    print(f\"   Sample names: {list(catalog_names)[:3]}\")\n",
    "    \n",
    "    # Get all commodity names from products\n",
    "    product_names = products_df['UNSPSC Commodity Name'].str.strip().str.lower()\n",
    "    unique_product_names = set(product_names)\n",
    "    \n",
    "    print(f\"\\n2️ Products Info:\")\n",
    "    print(f\"   Total products: {len(products_df)}\")\n",
    "    print(f\"   Unique commodity names: {len(unique_product_names)}\")\n",
    "    print(f\"   Sample names: {list(unique_product_names)[:3]}\")\n",
    "    \n",
    "    # Check matches\n",
    "    matches = unique_product_names.intersection(catalog_names)\n",
    "    missing = unique_product_names - catalog_names\n",
    "    \n",
    "    print(f\"\\n3️ Matching Analysis:\")\n",
    "    print(f\"    Matching names: {len(matches)}/{len(unique_product_names)}\")\n",
    "    print(f\"    Missing from catalog: {len(missing)}\")\n",
    "    \n",
    "    if missing:\n",
    "        print(f\"\\n   Missing names (first 5):\")\n",
    "        for name in list(missing)[:5]:\n",
    "            print(f\"      - '{name}'\")\n",
    "    \n",
    "    match_rate = len(matches) / len(unique_product_names) * 100 if unique_product_names else 0\n",
    "    print(f\"\\n   Match rate: {match_rate:.1f}%\")\n",
    "    \n",
    "    if match_rate < 100:\n",
    "        print(f\"\\n    WARNING: Not all product names found in catalog!\")\n",
    "        print(f\"   This will cause evaluation to skip {len(missing)} unique commodities\")\n",
    "    \n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return {\n",
    "        'total_products': len(products_df),\n",
    "        'unique_names': len(unique_product_names),\n",
    "        'matches': len(matches),\n",
    "        'missing': len(missing),\n",
    "        'match_rate': match_rate\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# RUN COMPLETE EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\" Step 1: Verifying data compatibility...\")\n",
    "compatibility = verify_data_compatibility(products_df, df)\n",
    "\n",
    "print(\"\\n🔧 Step 2: Initializing evaluator...\")\n",
    "evaluator = ProductEvaluator(products_df, df, retriever, reranker, merger, cleaner)\n",
    "\n",
    "print(\"\\n Step 3: Running evaluation...\")\n",
    "results = evaluator.evaluate(retrieve_k=50, rerank_k=20, top_k_list=[1, 5, 10])\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL EVALUATION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for metric, value in results.items():\n",
    "    if isinstance(value, (int, float)):\n",
    "        if metric in [\"Total Evaluated\", \"Skipped\"]:\n",
    "            print(f\"{metric:25s}: {value}\")\n",
    "        else:\n",
    "            print(f\"{metric:25s}: {value:6.2f}%\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Sanity check\n",
    "if 'Top-1 Accuracy' in results and results.get('Segment Acc @1', 0) > 0:\n",
    "    top1 = results['Top-1 Accuracy']\n",
    "    seg1 = results['Segment Acc @1']\n",
    "    \n",
    "    print(f\"\\n SANITY CHECK:\")\n",
    "    print(f\"   Top-1 Accuracy: {top1:.1f}%\")\n",
    "    print(f\"   Segment Acc @1: {seg1:.1f}%\")\n",
    "    \n",
    "    if seg1 >= top1:\n",
    "        print(f\"    PASS: Segment ≥ Commodity (as expected)\")\n",
    "    else:\n",
    "        print(f\"    FAIL: Segment < Commodity (shouldn't happen!)\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\" All classes are defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34d8080b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔧 Initializing components...\n",
      " BM25 index ready\n",
      " Cross-encoder loaded on cpu\n",
      " All components are initialized\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n🔧 Initializing components...\")\n",
    "\n",
    "cleaner = TextCleaner(remove_arbitrary_alphanum=False)\n",
    "retriever = HybridRetriever(df, loaded_vectorstore, embeddings, cleaner=cleaner)\n",
    "reranker = CrossEncoderReranker()\n",
    "merger = ScoreMerger(alpha=0.4, beta=0.6)\n",
    "\n",
    "print(\" All components are initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07974c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧪 Testing on a single product...\n",
      "Product: BW RG2PV75H6X 75 GAL LP GAS POWER VENTED WATER HEATER STANDARD W/SIDE CONNECTIONS FOR SPACE HTG 76KBTU 6YR 70\"\"H X 26\"\"DIA\n",
      "Retrieved 100 candidates\n",
      "Reranked to top 10\n",
      "\n",
      " Top 5 Predictions:\n",
      "1. Gas fueled fireplace B vent (Score: 0.6084)\n",
      "2. Gas turbine generator (Score: 0.4500)\n",
      "3. Gas turbine control panels (Score: 0.4472)\n",
      "4. Space heaters (Score: 0.3888)\n",
      "5. Gas generators (Score: 0.3794)\n",
      "\n",
      " The Ground Truth: Domestic water heaters\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Testing on a single product...\")\n",
    "\n",
    "test_description = products_df.iloc[0]['Original Description']\n",
    "print(f\"Product: {test_description}\")\n",
    "\n",
    "candidates = retriever.retrieve(test_description, top_k=50)\n",
    "print(f\"Retrieved {len(candidates)} candidates\")\n",
    "\n",
    "candidates = reranker.rerank(test_description, candidates, top_n=10)\n",
    "print(f\"Reranked to top {len(candidates)}\")\n",
    "\n",
    "final_candidates = merger.merge(candidates)\n",
    "\n",
    "print(\"\\n Top 5 Predictions:\")\n",
    "for i, c in enumerate(final_candidates[:5], 1):\n",
    "    print(f\"{i}. {c['commodity_name']} (Score: {c['final_score']:.4f})\")\n",
    "\n",
    "print(f\"\\nThe Ground Truth: {products_df.iloc[0].get('UNSPSC Commodity Name', 'N/A')}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbeb9099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RUNNING FULL EVALUATION:\n",
      "======================================================================\n",
      "<__main__.ProductEvaluator object at 0x000001754CAFD810>\n",
      "{'error': 'No valid products to evaluate'}\n",
      "\n",
      "======================================================================\n",
      "EVALUATION RESULTS:\n",
      "======================================================================\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RUNNING FULL EVALUATION:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "evaluator = ProductEvaluator(products_df,df,retriever, reranker, merger, cleaner)\n",
    "results = evaluator.evaluate(retrieve_k=50, rerank_k=20, top_k_list=[1, 5, 10])\n",
    "print(evaluator)\n",
    "print(results)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EVALUATION RESULTS:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for metric, value in results.items():\n",
    "    if isinstance(value, (int, float)):\n",
    "        if metric == \"Total Evaluated\":\n",
    "            print(f\"{metric:25s}: {value}\")\n",
    "        else:\n",
    "            print(f\"{metric:25s}: {value:6.2f}%\")\n",
    "\n",
    "print(\"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925ba5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV\n",
    "results_df = pd.DataFrame([results])\n",
    "results_df.to_csv(\"evaluation_results.csv\", index=False)\n",
    "print(\" Results saved to evaluation_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05717ede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
